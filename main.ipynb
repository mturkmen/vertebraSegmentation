#Import Libraries
import os
import sys
import numpy as np
import pandas as pd
from glob import glob
from PIL import Image
import cv2
import re
import gc
from tqdm import tqdm
import math

import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle

import skimage.transform as skTrans
from skimage import exposure

import albumentations as alb
from albumentations.pytorch import ToTensorV2

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
from torch.cuda.amp import autocast, GradScaler
from torch.optim.lr_scheduler import OneCycleLR, CosineAnnealingWarmRestarts

import tensorflow as tf

from monai.transforms import Resize
import monai.transforms as transforms
from monai.networks.nets import resnet18, resnet101

import segmentation_models_pytorch as smp

from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold, StratifiedKFold

import warnings
warnings.filterwarnings("ignore")
Config
SEED = 1927550
IMG_SIZE = 352
BATCH = 5
EPOCH = 50
CLASS = 7
hidden1 = 128
hidden2 = 64
KAGGLE = True
channel_3 = True
tot_slice = 30
best_loss = 1
device = 'cuda' if torch.cuda.is_available() else 'cpu'
encoder_backbone = 'resnet101'

trainlosslog = []
trainacclog = []
validlosslog = []
validacclog = []
if KAGGLE:
    work_path = '/kaggle/input'
else:
    work_path = '/content/drive/MyDrive/Colab_Notebooks'

base_path = f'{work_path}/stage-2-preprocessed-zip'
train_df = pd.read_csv(f'{work_path}/rsna-2022-cervical-spine-fracture-detection/train.csv')

#stage2_prep_list = os.listdir(f'{base_path}/stage2-prep')
stage2_prep_list = os.listdir(base_path)
stage2_prep_list = [os.path.splitext(os.path.basename(prep_path))[0] for prep_path in stage2_prep_list]
stage2_prep_uid = [prep_path.split('_')[0] for prep_path in stage2_prep_list]
voxel_df = pd.DataFrame(list(zip(stage2_prep_list, stage2_prep_uid)), columns=['id', 'StudyInstanceUID'])

kf = KFold(5)
for fold, (train_idx, valid_idx) in enumerate(kf.split(voxel_df, voxel_df)):
    voxel_df.loc[valid_idx, 'fold'] = fold

df_train = voxel_df[voxel_df['fold'] != fold].reset_index(drop=True)
df_valid = voxel_df[voxel_df['fold'] == fold].reset_index(drop=True)
seg_revert = [
    '1.2.826.0.1.3680043.1363',
    '1.2.826.0.1.3680043.20120',
    '1.2.826.0.1.3680043.2243',
    '1.2.826.0.1.3680043.24606',
    '1.2.826.0.1.3680043.32071'
]


# check the image size
# find the most sized image or the average
img_size = []
for idx in range(len(voxel_df)):
    loc = voxel_df.loc[idx]
    id_ = loc['id']
    path = f'{base_path}/{id_}.npz'
    
    img = np.load(path)['arr_0']
    img_size.append(img.shape[1]) # equivalent image size for both width and height
appr_img_size = [round(size/10)*10 for size in img_size]
unique, count = np.unique(appr_img_size, return_counts=True)

plt.bar(unique, count)

total = 0
total_count = 0
for idx in range(len(unique)):
    total += unique[idx] * count[idx]
    total_count += count[idx]

mean = total / total_count
print('Mean value:',mean)
Mean value: 349.3022159358793

#Useful Functions
# apply seed
def seed_everything(seed):
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
data_transforms = {
    'train': alb.Compose([
                alb.Resize(IMG_SIZE, IMG_SIZE),
                alb.HorizontalFlip(p=0.5),
                alb.VerticalFlip(p=0.5),
                alb.Transpose(p=0.5),
                alb.RandomBrightness(limit=0.1, p=0.7),
                alb.ShiftScaleRotate(shift_limit=0.3, scale_limit=0.3, rotate_limit=45, border_mode=4, p=0.7),
                alb.OneOf([
                    alb.MotionBlur(blur_limit=3),
                    alb.MedianBlur(blur_limit=3),
                    alb.GaussianBlur(blur_limit=3),
                    alb.GaussNoise(var_limit=(3.0, 9.0))
                ], p=0.5),
                alb.OneOf([
                    alb.GridDistortion(num_steps=5, distort_limit=1.),
                    alb.OpticalDistortion(distort_limit=1.)
                ], p=0.5),
                alb.Sharpen(alpha=(0.3, 0.5), p=0.7)
             ]),
    'valid': alb.Compose([alb.Resize(IMG_SIZE, IMG_SIZE)])
}

bad_scans = ['1.2.826.0.1.3680043.20574','1.2.826.0.1.3680043.29952', '1.2.826.0.1.368004.23904']

for uid in bad_scans:
    train_df.drop(train_df[train_df['StudyInstanceUID']==uid].index, axis=0, inplace=True)
for uid in bad_scans:
    voxel_df.drop(voxel_df[voxel_df['StudyInstanceUID']==uid].index, axis=0, inplace=True)
#Dataset Class
# extract image and label of the given data
class CustomDataset(torch.utils.data.Dataset):
    # Initialize
    def __init__(self, voxel_df=df_train, train_df=train_df, transform=None, test=False):
        super().__init__()
        self.voxel_df = voxel_df
        self.train_df = train_df
        self.transform = transform
        self.test = test
    
    def __getitem__(self, index):
        voxel_UID = self.voxel_df.iloc[index]
        uid = voxel_UID['id'].split('_')[0]
        label_df = self.train_df 

        #print(voxel_UID['id'])
        
        #imgs = np.load(f'{base_path}/stage2-prep/{voxel_UID.id}.npz')['arr_0']
        imgs = np.load(f'{base_path}/{voxel_UID.id}.npz')['arr_0'] # 80 X img_size X img_size
        imgs = imgs.transpose(1, 2, 0) # img_size X img_size X 80
        
        if self.transform is not None:
            trans = self.transform(image=imgs)
            imgs = trans['image']
        
        imgs = imgs.transpose(2, 0, 1) # 80 X 512 X 512
        vertebrae = voxel_UID['id'].split('_')[1] # C1; C2; C3; C4; C5; C6; C7
        if self.test == True:
            return torch.tensor(np.array(imgs/255.0, dtype=np.float32)).float(), [uid, vertebrae]
        
        label = label_df[label_df['StudyInstanceUID'] == uid][vertebrae].values.astype('float32') # either 0 or 1
        return torch.tensor(np.array(imgs/255.0, dtype=np.float32)).float(), torch.tensor(label).float()
       
    # Length of dataset
    def __len__(self):
        return len(self.voxel_df)
#Test Dataset
def plot_batch(imgs, size=40):
    #plt.figure(figsize=(5*5, 5*(40//5)))
    fig, axs = plt.subplots(size//5, 5, figsize=(5*5, size))
    
    for idx in range(size):
        #plt.subplot(idx//5+1, idx%5+1, (idx//5+1, idx%5+1))
        img = imgs[idx,].numpy()*255.0
        img = img.astype('uint8')
        axs[idx//5, idx%5].imshow(img, cmap='bone')
        #plt.imshow(img, cmap='bone')
        
    plt.tight_layout()
    plt.show()
test_dataset = CustomDataset(voxel_df=voxel_df, train_df=train_df, transform=data_transforms['valid'], test=True)
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)
imgs, labels = next(iter(test_loader))
print(labels)
plot_batch(imgs[0], size=30)
[('1.2.826.0.1.3680043.15623',), ('C7',)]

imgs, labels = next(iter(test_loader))
print(labels)
plot_batch(imgs[0], size=30)
[('1.2.826.0.1.3680043.20647',), ('C4',)]

#LSTM Model
# important to have a bigger backbone
# ResNet101 encoder backbone + UNet decoder => CrackNet
class ClassificationModel(nn.Module):
    def __init__(self):
        super(ClassificationModel, self).__init__()
        self.segmodel = smp.Unet(              # cnn
            encoder_backbone,                  # resnet101 backbone
            encoder_weights='imagenet',        # pretrained-weight = imagenet
            in_channels=tot_slice,             # in channels of 40*2
            classes=CLASS,                     # output channel be 7 from C1 to C7
            activation=None,
        )
        self.lstm = nn.LSTM( # output = (batch, sequence length, dimension * )
            input_size=(IMG_SIZE*IMG_SIZE), # 512 * 512 * 40(channel)
            hidden_size=hidden1, 
            num_layers=2, # num_layer = 2 if bidirectional = True. 1 otherwise
            dropout=0., 
            bidirectional=True, 
            batch_first=True # (batch_dimension, segment_dimension, feature_dimension)
        )
        self.head = nn.Sequential(
            nn.Linear(CLASS*(hidden1*2), IMG_SIZE), # dimensions, input image
            #nn.Linear(CLASS*512*512, 512),
            nn.BatchNorm1d(IMG_SIZE),
            nn.Dropout(0.3),
            nn.LeakyReLU(0.1),
            nn.Linear(IMG_SIZE, 1),
        )
    
    # input: (batch_size, tot_slice, image_size, image_size)
    def forward(self, x):
        batch_size = x.size(0)
        img_size = x.size(2) # or x.size(3); equal value
        
        x = self.segmodel(x)
        x = x.view(batch_size, CLASS, -1)
        # input: batch size, sequence length, input image size
        x,_ = self.lstm(x)
        x = x.contiguous().view(batch_size, -1)
        x = self.head(x)
        
        return x
#Settings
train_dataset = CustomDataset(voxel_df=df_train, train_df=train_df, transform=data_transforms['train'], test=False)
valid_dataset = CustomDataset(voxel_df=df_valid, train_df=train_df, transform=data_transforms['valid'], test=False)
train_loader = DataLoader(train_dataset, batch_size=BATCH, shuffle=True)
valid_loader = DataLoader(valid_dataset, batch_size=BATCH, shuffle=True)
# model setting
model = ClassificationModel()
model.to(device)
#model.load_state_dict(torch.load('/kaggle/input/stage2-cracknet-lstm-yolo-window/stage2_cracknet_best.ckpt'))

# Adam optimizer
optimizer = optim.AdamW(params=model.parameters(), lr=5e-5, weight_decay=1e-5)


# Replicate competition metric (https://www.kaggle.com/competitions/rsna-2022-cervical-spine-fracture-detection/discussion/341854)
loss_fn = F.binary_cross_entropy_with_logits

# The logits created from model training is either 0 or 1 for only one vertebrae
competition_weights = {
    '-' : torch.tensor(1, dtype=torch.float, device=device),
    '+' : torch.tensor(2, dtype=torch.float, device=device),
}

# with row-wise weights normalization (https://www.kaggle.com/competitions/rsna-2022-cervical-spine-fracture-detection/discussion/344565)
def competiton_loss_row_norm(y_hat, y):
    loss = loss_fn(y_hat.view(-1), y.to(y_hat.dtype).view(-1))
    weights = y * competition_weights['+'] + (1 - y) * competition_weights['-']
    loss = (loss * weights).sum(axis=1)
    w_sum = weights.sum(axis=1)
    loss = torch.div(loss, w_sum)
    return loss.mean()
#Training
def train(model, dataloader, optimizer):
    model.train()
    scaler = GradScaler()
    #scheduler = OneCycleLR(optimizer, max_lr=0.0005, epochs=1, steps_per_epoch=len(df_train), pct_start=0.3)
    
    train_loss = []
    train_acc = []
    
    for imgs, label in tqdm(dataloader):
        # set the gradient to 0 at initial
        optimizer.zero_grad()

        # forward data, making sure the data and model are on the same device
        with autocast(enabled=True):
            logits = model(imgs.to(device))
            loss = competiton_loss_row_norm(logits, label.to(device))
        
        #print('argmax:',logits.detach().cpu().numpy().argmax(axis=1))
        #print('max:',logits.detach().cpu().numpy().max(axis=1))
        #print('truth:',label.numpy())
        acc = (logits.argmax(dim=-1) == label.to(device)).float().mean()

        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        #scheduler.step()
        
        train_loss.append(loss.item())
        train_acc.append(acc)
        
    train_loss = sum(train_loss) / len(train_loss)
    train_acc = sum(train_acc) / len(train_acc)
    
    return train_loss, train_acc
def validation(model, dataloader, optimizer):
    model.eval()
    valid_loss = []
    valid_acc = []

    for imgs, label in tqdm(dataloader):
        # no need gradient in validation
        # use torch.no_grad() accelerates the forward process
        with torch.no_grad():
            logits = model(imgs.to(device))
        
        loss = competiton_loss_row_norm(logits, label.to(device))
        acc = (logits.argmax(dim=-1) == label.to(device)).float().mean()
        
        valid_loss.append(loss.item())
        valid_acc.append(acc)
    
    valid_loss = sum(valid_loss) / len(valid_loss)
    valid_acc = sum(valid_acc) / len(valid_acc)
    
    return valid_loss, valid_acc
seed_everything(SEED)

# initialize the best values to save
best_train_loss = 0
best_train_acc = 0
best_valid_loss = 0
best_valid_acc = 0

best_epoch = 0
early_stop_count = 0

scheduler = CosineAnnealingWarmRestarts(optimizer, EPOCH, eta_min=5e-6)

# start training
for epoch in range(EPOCH):
    print(f'### Epoch: {epoch+1} ###')
    train_loss, train_acc = train(model, train_loader, optimizer)
    print(f'[ Train | {epoch + 1:03d}/{EPOCH:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}')
    valid_loss, valid_acc = validation(model, valid_loader, optimizer)
    print(f'[ Valid | {epoch + 1:03d}/{EPOCH:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}')
    print()
    
    scheduler.step()
    
    # save train and valid logs
    trainlosslog.append(train_loss)
    trainacclog.append(train_acc.cpu().data.numpy())
    validlosslog.append(valid_loss)
    validacclog.append(valid_acc.cpu().data.numpy())
    
    # save models
    if valid_loss < best_loss:
        # save highest values
        best_train_loss, best_train_acc = train_loss, train_acc
        best_valid_loss, best_valid_acc = valid_loss, valid_acc
        best_epoch = epoch
        
        # save model
        torch.save(model.state_dict(), "stage2_cracknet_best.ckpt") # only save best to prevent output memory exceed error
        # reset values
        best_loss = valid_loss
        early_stop_count = 0
    
    """if early_stop_count > 10:
        print('Accuracy not increasing. Early Stopping...')
        break"""
    
    early_stop_count = early_stop_count + 1

print()
print(f"[ Best Train | {best_epoch+1:03d} / {EPOCH:03d} ] loss = {best_train_loss:.8f}, acc = {best_train_acc:.8f}")
print(f"[ Best Valid | {best_epoch+1:03d} / {EPOCH:03d} ] loss = {best_valid_loss:.8f}, acc = {best_valid_acc:.8f}")
log_df = pd.DataFrame(
    {
        'trainLoss': trainlosslog,
        'trainAcc': trainacclog,
        'validLoss': validlosslog,
        'validAcc': validacclog
    })

log_df.to_csv('Logs.csv')
 
